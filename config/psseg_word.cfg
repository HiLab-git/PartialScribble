[dataset]
# tensor type (float or double)
tensor_type    = float
task_type      = seg
supervise_type = weak_sup

train_dir = data/Word/Word_3d
train_csv = data/Word/Word_3d/train.csv
valid_csv = data/Word/Word_3d/valid.csv
test_csv  = data/Word/Word_3d/test.csv
train_dim = 3
train_label_key = scribble
valid_dim = 3
test_dim  = 3
train_batch_size = 2

# data transforms
train_transform = [RandomCrop, NormalizeWithMeanStd]
valid_transform = [NormalizeWithMeanStd]
test_transform = [NormalizeWithMeanStd]

NormalizeWithMeanStd_channels = [0]
RandomCrop_output_size = [64, 80, 80]


[network]
# type of network
net_type = mTDNetIdpSk_3D

in_chns          = 1
class_num        = 8
same_kernal_szie = 1
is_deepSupervision = True

[training]
# list of gpus
gpus       = [0]

loss_type     = CrossEntropyLoss

# for optimizers
optimizer     = SGD
nesterov      = False
learning_rate = 1e-2
momentum      = 0.9
weight_decay  = 1e-4

# for lr schedular 
lr_scheduler  = PolynomialLR
lr_power      = 0.9
early_stop_patience = 10000

ckpt_dir    = model/word_psseg

# start iter
iter_start = 0
iter_max   = 30000
iter_valid = 100
iter_save  = [10000, 20000, 30000]

# hyper-parameters
alpha = 10.0 
gamma = 0.01 
consistencty = 1.0
consistency_rampup = 60.0
consistency_rampepoch = 1000



[weakly_supervised_learning]
method_name    = PSSEG




[testing]
# list of gpus
gpus       = [0]

# checkpoint mode can be [0-latest, 1-best, 2-specified]
ckpt_mode         = 1
output_dir        = result/word_psseg

sliding_window_enable = True
sliding_window_size = [64, 80, 80]